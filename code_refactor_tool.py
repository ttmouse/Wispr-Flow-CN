#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä»£ç é‡æ„å·¥å…· - åˆ†æå’Œæ¸…ç†é¡¹ç›®ä¸­çš„å†—ä½™ä»£ç 
"""

import os
import re
import ast
import json
from pathlib import Path
from typing import Dict, List, Set, Tuple, Any
from collections import defaultdict, Counter
from datetime import datetime
import argparse

class CodeRefactorTool:
    """ä»£ç é‡æ„åˆ†æå·¥å…·"""
    
    def __init__(self, project_root: str):
        self.project_root = Path(project_root)
        self.src_dir = self.project_root / "src"
        self.analysis_report = ""
        
    def analyze_project(self) -> Dict[str, Any]:
        """åˆ†æé¡¹ç›®ä¸­çš„å†—ä½™ä»£ç """
        print("ğŸ” å¼€å§‹åˆ†æé¡¹ç›®å†—ä½™ä»£ç ...")
        
        analysis_data = {
            'duplicate_functions': self._find_duplicate_functions(),
            'cleanup_methods': self._analyze_cleanup_methods(),
            'permission_checks': self._find_permission_checks(),
            'import_redundancy': self._analyze_import_redundancy(),
            'exception_patterns': self._find_exception_patterns(),
            'hardcoded_values': self._find_hardcoded_values()
        }
        
        self._generate_analysis_report(analysis_data)
        return analysis_data
    
    def _find_duplicate_functions(self) -> Dict[str, List[str]]:
        """æŸ¥æ‰¾é‡å¤çš„å‡½æ•°å®šä¹‰"""
        print("\nğŸ”„ æŸ¥æ‰¾é‡å¤å‡½æ•°å®šä¹‰...")
        
        function_definitions = defaultdict(list)
        
        for py_file in self.src_dir.rglob("*.py"):
            try:
                with open(py_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # ä½¿ç”¨ASTè§£æå‡½æ•°å®šä¹‰
                tree = ast.parse(content)
                for node in ast.walk(tree):
                    if isinstance(node, ast.FunctionDef):
                        function_definitions[node.name].append(str(py_file))
                        
            except Exception as e:
                print(f"âš ï¸ è§£ææ–‡ä»¶å¤±è´¥ {py_file}: {e}")
        
        # æ‰¾å‡ºé‡å¤çš„å‡½æ•°
        duplicates = {func: files for func, files in function_definitions.items() if len(files) > 1}
        
        if duplicates:
            print(f"  ğŸ¯ å‘ç° {len(duplicates)} ä¸ªé‡å¤å‡½æ•°:")
            for func, files in duplicates.items():
                print(f"    - {func}: {len(files)} ä¸ªæ–‡ä»¶")
        else:
            print("  âœ… æœªå‘ç°é‡å¤å‡½æ•°")
            
        return duplicates
    
    def _analyze_cleanup_methods(self) -> Dict[str, Dict[str, Any]]:
        """åˆ†æcleanupæ–¹æ³•çš„å®ç°"""
        print("\nğŸ§¹ åˆ†æcleanupæ–¹æ³•...")
        
        cleanup_methods = {}
        
        for py_file in self.src_dir.rglob("*.py"):
            try:
                with open(py_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # æŸ¥æ‰¾cleanupæ–¹æ³•
                cleanup_pattern = r'def\s+(cleanup|_cleanup|cleanup_resources|_quick_cleanup)\s*\([^)]*\):'
                matches = re.finditer(cleanup_pattern, content)
                
                for match in matches:
                    method_name = match.group(1)
                    # è®¡ç®—æ–¹æ³•è¡Œæ•°
                    lines_before = content[:match.start()].count('\n') + 1
                    method_content = self._extract_method_content(content, match.start())
                    lines_count = method_content.count('\n') + 1
                    
                    cleanup_methods[str(py_file)] = {
                        'method_name': method_name,
                        'start_line': lines_before,
                        'lines': lines_count,
                        'content_preview': method_content[:200] + '...' if len(method_content) > 200 else method_content
                    }
                    
            except Exception as e:
                print(f"âš ï¸ åˆ†æcleanupæ–¹æ³•å¤±è´¥ {py_file}: {e}")
        
        print(f"  ğŸ¯ å‘ç° {len(cleanup_methods)} ä¸ªcleanupæ–¹æ³•")
        return cleanup_methods
    
    def _extract_method_content(self, content: str, start_pos: int) -> str:
        """æå–æ–¹æ³•å†…å®¹"""
        lines = content[start_pos:].split('\n')
        method_lines = [lines[0]]  # æ–¹æ³•å®šä¹‰è¡Œ
        
        if len(lines) > 1:
            # æ‰¾åˆ°æ–¹æ³•çš„ç¼©è¿›çº§åˆ«
            base_indent = len(lines[1]) - len(lines[1].lstrip()) if lines[1].strip() else 4
            
            for line in lines[1:]:
                if line.strip() == "":
                    method_lines.append(line)
                    continue
                    
                current_indent = len(line) - len(line.lstrip())
                if current_indent <= base_indent and line.strip():
                    break
                    
                method_lines.append(line)
                
        return '\n'.join(method_lines)
    
    def _find_permission_checks(self) -> Dict[str, List[str]]:
        """æŸ¥æ‰¾æƒé™æ£€æŸ¥ç›¸å…³ä»£ç """
        print("\nğŸ” æŸ¥æ‰¾æƒé™æ£€æŸ¥é€»è¾‘...")
        
        permission_patterns = {
            'check_permissions': r'def\s+.*check.*permission',
            'accessibility_check': r'accessibility|è¾…åŠ©åŠŸèƒ½',
            'microphone_check': r'microphone|éº¦å…‹é£|å½•éŸ³æƒé™',
            'system_events': r'system.*event|ç³»ç»Ÿäº‹ä»¶'
        }
        
        permission_checks = {pattern: [] for pattern in permission_patterns}
        
        for py_file in self.src_dir.rglob("*.py"):
            try:
                with open(py_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                for pattern_name, pattern in permission_patterns.items():
                    if re.search(pattern, content, re.IGNORECASE):
                        permission_checks[pattern_name].append(str(py_file))
                        
            except Exception as e:
                print(f"âš ï¸ æŸ¥æ‰¾æƒé™æ£€æŸ¥å¤±è´¥ {py_file}: {e}")
        
        for pattern, files in permission_checks.items():
            if files:
                print(f"  ğŸ¯ {pattern}: {len(files)} ä¸ªæ–‡ä»¶")
        
        return permission_checks
    
    def _analyze_import_redundancy(self) -> Dict[str, List[str]]:
        """åˆ†æå¯¼å…¥è¯­å¥å†—ä½™"""
        print("\nğŸ“¦ åˆ†æå¯¼å…¥è¯­å¥å†—ä½™...")
        
        import_statements = defaultdict(list)
        
        for py_file in self.src_dir.rglob("*.py"):
            try:
                with open(py_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # æŸ¥æ‰¾importè¯­å¥
                import_patterns = [
                    r'^import\s+([\w\.]+)',
                    r'^from\s+([\w\.]+)\s+import'
                ]
                
                for pattern in import_patterns:
                    matches = re.finditer(pattern, content, re.MULTILINE)
                    for match in matches:
                        module = match.group(1)
                        import_statements[module].append(str(py_file))
                        
            except Exception as e:
                print(f"âš ï¸ åˆ†æå¯¼å…¥è¯­å¥å¤±è´¥ {py_file}: {e}")
        
        # æ‰¾å‡ºé«˜é¢‘å¯¼å…¥
        common_imports = {imp: files for imp, files in import_statements.items() if len(files) >= 3}
        
        print(f"  ğŸ¯ å‘ç° {len(common_imports)} ä¸ªé«˜é¢‘å¯¼å…¥æ¨¡å—")
        return common_imports
    
    def _find_exception_patterns(self) -> Dict[str, List[str]]:
        """æŸ¥æ‰¾å¼‚å¸¸å¤„ç†æ¨¡å¼"""
        print("\nâš ï¸ æŸ¥æ‰¾å¼‚å¸¸å¤„ç†æ¨¡å¼...")
        
        exception_patterns = {
            'generic_except': r'except\s*:',
            'broad_exception': r'except\s+Exception\s*:',
            'try_except_pass': r'except[^:]*:\s*pass',
            'exception_logging': r'except[^:]*:.*(?:print|log|logger)'
        }
        
        exception_usage = {pattern: [] for pattern in exception_patterns}
        
        for py_file in self.src_dir.rglob("*.py"):
            try:
                with open(py_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                for pattern_name, pattern in exception_patterns.items():
                    if re.search(pattern, content, re.MULTILINE | re.DOTALL):
                        exception_usage[pattern_name].append(str(py_file))
                        
            except Exception as e:
                print(f"âš ï¸ æŸ¥æ‰¾å¼‚å¸¸å¤„ç†å¤±è´¥ {py_file}: {e}")
        
        for pattern, files in exception_usage.items():
            if files:
                print(f"  ğŸ¯ {pattern}: {len(files)} ä¸ªæ–‡ä»¶")
        
        return exception_usage
    
    def _find_hardcoded_values(self) -> Dict[str, List[Tuple[str, str]]]:
        """æŸ¥æ‰¾ç¡¬ç¼–ç å€¼"""
        print("\nğŸ”¢ æŸ¥æ‰¾ç¡¬ç¼–ç å€¼...")
        
        hardcoded_patterns = {
            'magic_numbers': r'\\b(?:0\\.3|3000|5000|8000|16000|30|50|100|200|300|500|1000)\\b',
            'file_paths': r'["\'][^"\'\n]*\\.(wav|log|json|txt|py)["\']',
            'app_names': r'["\'](?:Dou-flow|ASR-FunASR|Music|Spotify|Chrome|Safari)["\']',
            'error_messages': r'["\'][^"\'\n]*(?:å¤±è´¥|é”™è¯¯|Error|Failed)[^"\'\n]*["\']'
        }
        
        hardcoded_values = {pattern: [] for pattern in hardcoded_patterns}
        
        for py_file in self.src_dir.rglob("*.py"):
            try:
                with open(py_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                for pattern_name, pattern in hardcoded_patterns.items():
                    matches = re.finditer(pattern, content)
                    for match in matches:
                        hardcoded_values[pattern_name].append((str(py_file), match.group()))
                        
            except Exception as e:
                print(f"âš ï¸ æŸ¥æ‰¾ç¡¬ç¼–ç å€¼å¤±è´¥ {py_file}: {e}")
        
        for pattern, values in hardcoded_values.items():
            if values:
                print(f"  ğŸ¯ {pattern}: {len(values)} ä¸ª")
        
        return hardcoded_values
    
    def _generate_analysis_report(self, analysis_data: Dict):
        """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
        print("\nğŸ“Š ç”Ÿæˆåˆ†ææŠ¥å‘Š...")
        
        report_content = f"""
# ä»£ç å†—ä½™åˆ†ææŠ¥å‘Š
ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
é¡¹ç›®è·¯å¾„: {self.project_root}

## ğŸ¯ ä¸»è¦å‘ç°

### 1. é‡å¤å‡½æ•°å®šä¹‰
"""
        
        # é‡å¤å‡½æ•°
        if analysis_data['duplicate_functions']:
            report_content += "\n**å‘ç°çš„é‡å¤å‡½æ•°:**\n"
            for func, files in analysis_data['duplicate_functions'].items():
                report_content += f"- `{func}` åœ¨ {len(files)} ä¸ªæ–‡ä»¶ä¸­é‡å¤:\n"
                for file in files:
                    report_content += f"  - {file}\n"
        else:
            report_content += "\nâœ… æœªå‘ç°é‡å¤çš„å‡½æ•°å®šä¹‰\n"
        
        # Cleanupæ–¹æ³•åˆ†æ
        report_content += "\n### 2. Cleanupæ–¹æ³•åˆ†æ\n"
        if analysis_data['cleanup_methods']:
            report_content += f"\n**æ‰¾åˆ° {len(analysis_data['cleanup_methods'])} ä¸ªcleanupæ–¹æ³•:**\n"
            for file, info in analysis_data['cleanup_methods'].items():
                report_content += f"- {file}: {info['lines']}è¡Œ\n"
        
        # æƒé™æ£€æŸ¥
        report_content += "\n### 3. æƒé™æ£€æŸ¥é€»è¾‘\n"
        for pattern, files in analysis_data['permission_checks'].items():
            if files:
                report_content += f"\n**{pattern}:** {len(files)} ä¸ªæ–‡ä»¶\n"
        
        # å¯¼å…¥å†—ä½™
        report_content += "\n### 4. å¯¼å…¥è¯­å¥å†—ä½™\n"
        common_imports = analysis_data['import_redundancy']
        if common_imports:
            report_content += "\n**é«˜é¢‘å¯¼å…¥è¯­å¥:**\n"
            for imp, files in sorted(common_imports.items(), key=lambda x: len(x[1]), reverse=True)[:10]:
                report_content += f"- `{imp}`: {len(files)} æ¬¡\n"
        
        # å¼‚å¸¸å¤„ç†
        report_content += "\n### 5. å¼‚å¸¸å¤„ç†æ¨¡å¼\n"
        for pattern, files in analysis_data['exception_patterns'].items():
            if files:
                report_content += f"- **{pattern}:** {len(files)} ä¸ªæ–‡ä»¶\n"
        
        # ç¡¬ç¼–ç å€¼
        report_content += "\n### 6. ç¡¬ç¼–ç å€¼ç»Ÿè®¡\n"
        for pattern, values in analysis_data['hardcoded_values'].items():
            if values:
                report_content += f"- **{pattern}:** {len(values)} ä¸ª\n"
        
        # ä¼˜åŒ–å»ºè®®
        report_content += self._generate_optimization_suggestions(analysis_data)
        
        # ä¿å­˜æŠ¥å‘Š
        report_file = self.project_root / "code_redundancy_analysis.md"
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        print(f"âœ… åˆ†ææŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
        self.analysis_report = report_content
    
    def _generate_optimization_suggestions(self, analysis_data: Dict) -> str:
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        suggestions = "\n\n## ğŸš€ ä¼˜åŒ–å»ºè®®\n\n"
        
        # 1. é‡å¤å‡½æ•°ä¼˜åŒ–
        if analysis_data['duplicate_functions']:
            suggestions += "### 1. é‡å¤å‡½æ•°ä¼˜åŒ–\n\n"
            
            # ç‰¹åˆ«å¤„ç†clean_html_tagså‡½æ•°
            for func, files in analysis_data['duplicate_functions'].items():
                if 'clean_html_tags' in func:
                    suggestions += "**ä¼˜å…ˆçº§ï¼šé«˜**\n"
                    suggestions += "- åˆ›å»º `src/utils/text_utils.py` ç»Ÿä¸€ç®¡ç†æ–‡æœ¬å¤„ç†å‡½æ•°\n"
                    suggestions += "- å°† `clean_html_tags` å‡½æ•°ç§»åŠ¨åˆ°å·¥å…·æ¨¡å—\n"
                    suggestions += "- æ›´æ–°æ‰€æœ‰å¼•ç”¨è¯¥å‡½æ•°çš„æ–‡ä»¶\n\n"
        
        # 2. Cleanupæ–¹æ³•ä¼˜åŒ–
        if len(analysis_data['cleanup_methods']) > 3:
            suggestions += "### 2. èµ„æºæ¸…ç†ä¼˜åŒ–\n\n"
            suggestions += "**ä¼˜å…ˆçº§ï¼šä¸­**\n"
            suggestions += "- åˆ›å»ºåŸºç¡€æ¸…ç†æ¥å£ `CleanupMixin`\n"
            suggestions += "- ç»Ÿä¸€æ¸…ç†æ–¹æ³•çš„å®ç°æ¨¡å¼\n"
            suggestions += "- æ·»åŠ æ¸…ç†çŠ¶æ€è·Ÿè¸ª\n\n"
        
        # 3. æƒé™æ£€æŸ¥ä¼˜åŒ–
        permission_files = sum(len(files) for files in analysis_data['permission_checks'].values())
        if permission_files > 2:
            suggestions += "### 3. æƒé™æ£€æŸ¥ä¼˜åŒ–\n\n"
            suggestions += "**ä¼˜å…ˆçº§ï¼šä¸­**\n"
            suggestions += "- åˆ›å»º `src/utils/permission_utils.py` ç»Ÿä¸€æƒé™æ£€æŸ¥\n"
            suggestions += "- å®ç°æƒé™çŠ¶æ€ç¼“å­˜æœºåˆ¶\n"
            suggestions += "- ç»Ÿä¸€æƒé™é”™è¯¯å¤„ç†\n\n"
        
        return suggestions
    
    def execute_high_priority_refactoring(self):
        """æ‰§è¡Œé«˜ä¼˜å…ˆçº§é‡æ„"""
        print("\nğŸš€ å¼€å§‹æ‰§è¡Œé«˜ä¼˜å…ˆçº§é‡æ„...")
        
        # 1. åˆ›å»ºå·¥å…·ç›®å½•
        utils_dir = self.src_dir / "utils"
        utils_dir.mkdir(exist_ok=True)
        
        # åˆ›å»º__init__.py
        init_file = utils_dir / "__init__.py"
        if not init_file.exists():
            init_file.write_text('"""å·¥å…·æ¨¡å—"""\n', encoding='utf-8')
        
        # 2. åˆ›å»ºtext_utils.py
        self._create_text_utils()
        
        # 3. åˆ›å»ºerror_handler.py
        self._create_error_handler()
        
        print("âœ… é«˜ä¼˜å…ˆçº§é‡æ„å®Œæˆ")
    
    def _create_text_utils(self):
        """åˆ›å»ºæ–‡æœ¬å¤„ç†å·¥å…·æ¨¡å—"""
        text_utils_content = '''
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ–‡æœ¬å¤„ç†å·¥å…·æ¨¡å—
ç»Ÿä¸€ç®¡ç†æ‰€æœ‰æ–‡æœ¬å¤„ç†ç›¸å…³çš„å‡½æ•°
"""

import re
import html

def clean_html_tags(text: str) -> str:
    """
    æ¸…ç†HTMLæ ‡ç­¾å’Œè§£ç HTMLå®ä½“
    
    Args:
        text: åŒ…å«HTMLæ ‡ç­¾çš„æ–‡æœ¬
        
    Returns:
        æ¸…ç†åçš„çº¯æ–‡æœ¬
    """
    if not text:
        return ""
    
    # ç§»é™¤HTMLæ ‡ç­¾
    clean_text = re.sub(r'<[^>]+>', '', text)
    
    # è§£ç HTMLå®ä½“
    clean_text = html.unescape(clean_text)
    
    # æ¸…ç†å¤šä½™çš„ç©ºç™½å­—ç¬¦
    clean_text = re.sub(r'\\s+', ' ', clean_text).strip()
    
    return clean_text

def normalize_text(text: str) -> str:
    """
    æ ‡å‡†åŒ–æ–‡æœ¬æ ¼å¼
    
    Args:
        text: åŸå§‹æ–‡æœ¬
        
    Returns:
        æ ‡å‡†åŒ–åçš„æ–‡æœ¬
    """
    if not text:
        return ""
    
    # ç»Ÿä¸€æ¢è¡Œç¬¦
    text = text.replace('\\r\\n', '\\n').replace('\\r', '\\n')
    
    # ç§»é™¤å¤šä½™ç©ºè¡Œ
    text = re.sub(r'\\n\\s*\\n', '\\n\\n', text)
    
    # æ¸…ç†é¦–å°¾ç©ºç™½
    text = text.strip()
    
    return text

def truncate_text(text: str, max_length: int = 100, suffix: str = "...") -> str:
    """
    æˆªæ–­æ–‡æœ¬åˆ°æŒ‡å®šé•¿åº¦
    
    Args:
        text: åŸå§‹æ–‡æœ¬
        max_length: æœ€å¤§é•¿åº¦
        suffix: æˆªæ–­åç¼€
        
    Returns:
        æˆªæ–­åçš„æ–‡æœ¬
    """
    if not text or len(text) <= max_length:
        return text
    
    return text[:max_length - len(suffix)] + suffix
'''
        
        text_utils_file = self.src_dir / "utils" / "text_utils.py"
        with open(text_utils_file, 'w', encoding='utf-8') as f:
            f.write(text_utils_content)
        
        print(f"âœ… åˆ›å»ºæ–‡æœ¬å·¥å…·æ¨¡å—: {text_utils_file}")
    
    def _create_error_handler(self):
        """åˆ›å»ºé”™è¯¯å¤„ç†å·¥å…·æ¨¡å—"""
        error_handler_content = '''
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é”™è¯¯å¤„ç†å·¥å…·æ¨¡å—
ç»Ÿä¸€ç®¡ç†å¼‚å¸¸å¤„ç†é€»è¾‘
"""

import functools
import logging
import traceback
from typing import Callable, Any, Optional

logger = logging.getLogger(__name__)

def handle_exceptions(default_return: Any = None, 
                     log_error: bool = True,
                     reraise: bool = False):
    """
    ç»Ÿä¸€å¼‚å¸¸å¤„ç†è£…é¥°å™¨
    
    Args:
        default_return: å¼‚å¸¸æ—¶çš„é»˜è®¤è¿”å›å€¼
        log_error: æ˜¯å¦è®°å½•é”™è¯¯æ—¥å¿—
        reraise: æ˜¯å¦é‡æ–°æŠ›å‡ºå¼‚å¸¸
    """
    def decorator(func: Callable) -> Callable:
        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            try:
                return func(*args, **kwargs)
            except Exception as e:
                if log_error:
                    logger.error(
                        f"å‡½æ•° {func.__name__} æ‰§è¡Œå¤±è´¥: {str(e)}\\n"
                        f"å‚æ•°: args={args}, kwargs={kwargs}\\n"
                        f"å †æ ˆ: {traceback.format_exc()}"
                    )
                
                if reraise:
                    raise
                    
                return default_return
        return wrapper
    return decorator

def safe_execute(func: Callable, 
                *args, 
                default_return: Any = None,
                log_error: bool = True,
                **kwargs) -> Any:
    """
    å®‰å…¨æ‰§è¡Œå‡½æ•°
    
    Args:
        func: è¦æ‰§è¡Œçš„å‡½æ•°
        *args: å‡½æ•°å‚æ•°
        default_return: å¼‚å¸¸æ—¶çš„é»˜è®¤è¿”å›å€¼
        log_error: æ˜¯å¦è®°å½•é”™è¯¯æ—¥å¿—
        **kwargs: å‡½æ•°å…³é”®å­—å‚æ•°
        
    Returns:
        å‡½æ•°æ‰§è¡Œç»“æœæˆ–é»˜è®¤è¿”å›å€¼
    """
    try:
        return func(*args, **kwargs)
    except Exception as e:
        if log_error:
            logger.error(
                f"å®‰å…¨æ‰§è¡Œå‡½æ•° {func.__name__} å¤±è´¥: {str(e)}\\n"
                f"å‚æ•°: args={args}, kwargs={kwargs}\\n"
                f"å †æ ˆ: {traceback.format_exc()}"
            )
        return default_return

class ErrorContext:
    """
    é”™è¯¯ä¸Šä¸‹æ–‡ç®¡ç†å™¨
    """
    
    def __init__(self, 
                 operation_name: str,
                 default_return: Any = None,
                 log_error: bool = True,
                 reraise: bool = False):
        self.operation_name = operation_name
        self.default_return = default_return
        self.log_error = log_error
        self.reraise = reraise
        self.result = None
        
    def __enter__(self):
        return self
        
    def __exit__(self, exc_type, exc_val, exc_tb):
        if exc_type is not None:
            if self.log_error:
                logger.error(
                    f"æ“ä½œ '{self.operation_name}' å¤±è´¥: {str(exc_val)}\\n"
                    f"å¼‚å¸¸ç±»å‹: {exc_type.__name__}\\n"
                    f"å †æ ˆ: {traceback.format_exc()}"
                )
            
            if not self.reraise:
                self.result = self.default_return
                return True  # æŠ‘åˆ¶å¼‚å¸¸
                
        return False  # ä¸æŠ‘åˆ¶å¼‚å¸¸
'''
        
        error_handler_file = self.src_dir / "utils" / "error_handler.py"
        with open(error_handler_file, 'w', encoding='utf-8') as f:
            f.write(error_handler_content)
        
        print(f"âœ… åˆ›å»ºé”™è¯¯å¤„ç†æ¨¡å—: {error_handler_file}")

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='ä»£ç é‡æ„å·¥å…·')
    parser.add_argument('project_path', help='é¡¹ç›®æ ¹ç›®å½•è·¯å¾„')
    parser.add_argument('--execute', action='store_true', help='æ‰§è¡Œé«˜ä¼˜å…ˆçº§é‡æ„')
    
    args = parser.parse_args()
    
    tool = CodeRefactorTool(args.project_path)
    
    # åˆ†æé¡¹ç›®
    analysis_data = tool.analyze_project()
    
    # æ‰§è¡Œé‡æ„ï¼ˆå¦‚æœæŒ‡å®šï¼‰
    if args.execute:
        tool.execute_high_priority_refactoring()
    
    print("\nğŸ‰ åˆ†æå®Œæˆï¼")
    print(f"ğŸ“„ æŸ¥çœ‹è¯¦ç»†æŠ¥å‘Š: {tool.project_root}/code_redundancy_analysis.md")

if __name__ == "__main__":
    main()