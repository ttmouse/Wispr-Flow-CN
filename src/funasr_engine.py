from funasr import AutoModel
import numpy as np
import os
import sys
import logging
import re
from contextlib import redirect_stdout, redirect_stderr
import io

# 设置 modelscope 日志级别为 WARNING，减少不必要的信息
logging.getLogger('modelscope').setLevel(logging.WARNING)

class FunASREngine:
    def __init__(self):
        try:
            # 获取应用程序的基础路径
            if getattr(sys, 'frozen', False):
                application_path = sys._MEIPASS
            else:
                application_path = os.path.dirname(os.path.abspath(__file__))
            
            print(f"应用程序路径: {application_path}")
            
            # 设置 MODELSCOPE_CACHE 环境变量
            cache_dir = os.path.join(application_path, 'modelscope', 'hub')
            os.environ['MODELSCOPE_CACHE'] = cache_dir
            print(f"模型缓存路径: {cache_dir}")
            
            # 初始化热词列表
            self.hotwords = []
            hotwords_file = os.path.join(os.path.dirname(application_path), "resources", "hotwords.txt")
            if os.path.exists(hotwords_file):
                with open(hotwords_file, 'r', encoding='utf-8') as f:
                    self.hotwords = [line.strip() for line in f if line.strip()]
                print(f"加载了 {len(self.hotwords)} 个热词")
            
            # 检查模型文件是否存在
            asr_model_dir = os.path.join(cache_dir, 'damo', 'speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch')
            punc_model_dir = os.path.join(cache_dir, 'damo', 'punc_ct-transformer_zh-cn-common-vocab272727-pytorch')
            
            print(f"ASR模型路径: {asr_model_dir}")
            print(f"标点模型路径: {punc_model_dir}")
            
            if not os.path.exists(asr_model_dir) or not os.path.exists(punc_model_dir):
                raise Exception(f"模型文件不存在: ASR模型: {os.path.exists(asr_model_dir)}, 标点模型: {os.path.exists(punc_model_dir)}")
            
            # 使用 redirect_stdout 来捕获输出
            f = io.StringIO()
            with redirect_stdout(f), redirect_stderr(f):
                print("开始加载ASR模型...")
                # 初始化语音识别模型
                self.model = AutoModel(
                    model=asr_model_dir,
                    model_revision="v2.0.4",
                    disable_update=True
                )
                print("ASR模型加载完成")
                
                print("开始加载标点模型...")
                # 初始化标点模型
                self.punc_model = AutoModel(
                    model=punc_model_dir,
                    model_revision="v2.0.4",
                    disable_update=True
                )
                print("标点模型加载完成")
                
        except Exception as e:
            error_msg = f"❌ 模型加载失败: {str(e)}\n"
            error_msg += f"系统路径: {sys.path}\n"
            error_msg += f"当前目录: {os.getcwd()}\n"
            error_msg += f"环境变量: MODELSCOPE_CACHE={os.environ.get('MODELSCOPE_CACHE', '未设置')}\n"
            print(error_msg)
            raise

    def transcribe(self, audio_data):
        """转写音频数据"""
        try:
            if audio_data.dtype != np.float32:
                audio_data = audio_data.astype(np.float32)
                
                
            # 使用 redirect_stdout 来捕获输出
            f = io.StringIO()
            with redirect_stdout(f), redirect_stderr(f):
                # 1. 语音识别
                result = self.model.generate(
                    input=audio_data,
                    batch_size_s=100,     # 减小批处理大小
                    use_itn=True,         # 启用逆文本正则化
                    mode='offline',      # 使用离线模式以提高准确率
                    decode_method='greedy_search',  # 使用贪婪搜索解码
                    disable_progress_bar=True,  # 禁用进度条
                    hotwords=self.hotwords if self.hotwords else None  # 使用热词列表
                )
            
            # 处理结果
            if isinstance(result, list) and len(result) > 0:
                text = result[0].get('text', '')
            elif isinstance(result, dict):
                text = result.get('text', '')
            else:
                text = str(result)
                
            # 检查结果中是否包含热词
            if self.hotwords:
                found_hotwords = [word for word in self.hotwords if word in text]
                if found_hotwords:
                    print(f"✓ 识别出的热词: {', '.join(found_hotwords)}")
            
            # 2. 添加标点
            with redirect_stdout(f), redirect_stderr(f):
                punc_result = self.punc_model.generate(
                    input=text,
                    disable_progress_bar=True,
                    batch_size=1,
                    mode='offline',      # 使用离线模式以提高准确率
                    cache_size=1000,     # 使用缓存加速
                    hotword_score=0.8,   # 提高热词权重
                    min_sentence_length=2 # 减小最小句子长度
                )
            if isinstance(punc_result, list) and len(punc_result) > 0:
                text = punc_result[0].get('text', text)
            elif isinstance(punc_result, dict):
                text = punc_result.get('text', text)
            
            # 3. 处理英文单词间的空格
            processed_text = self._process_text(text)
            
            return [{"text": processed_text}]
            
        except Exception as e:
            print(f"❌ 转写失败: {e}")
            raise

    def _process_text(self, text):
        """处理文本，添加英文单词间的空格"""
        # 1. 使用正则表达式分离英文单词
        def split_english_words(text):
            # 匹配连续的英文字母
            words = re.finditer(r'[a-zA-Z]+', text)
            result = []
            last_end = 0
            
            for match in words:
                start, end = match.span()
                # 添加非英文部分
                if start > last_end:
                    result.append(text[last_end:start])
                # 添加英文单词
                word = match.group()
                # 使用简单的规则分割英文单词
                # 比如 "whatareyou" -> "what are you"
                sub_words = []
                current_word = ""
                for i, char in enumerate(word.lower()):
                    current_word += char
                    # 常见的英文单词
                    common_words = {'what', 'are', 'you', 'doing', 'how', 'is', 'the', 'this', 'that', 'have', 'has', 'had', 'will', 'would', 'can', 'could', 'should', 'must', 'may', 'might', 'shall'}
                    # 如果当前积累的字母构成了一个常见单词，并且剩余的字母也可能构成单词
                    if current_word in common_words and i < len(word) - 1:
                        sub_words.append(current_word)
                        current_word = ""
                if current_word:
                    sub_words.append(current_word)
                result.append(' '.join(sub_words))
                last_end = end
            
            # 添加剩余的文本
            if last_end < len(text):
                result.append(text[last_end:])
            
            return ''.join(result)
        
        # 2. 处理文本
        processed_text = split_english_words(text)
        
        return processed_text

    def get_model_path(self):
        return "使用预训练模型"