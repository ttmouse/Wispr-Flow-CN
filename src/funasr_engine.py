from funasr import AutoModel
import numpy as np
import os
import sys
import logging
import re
from contextlib import redirect_stdout, redirect_stderr
import io

# è®¾ç½® modelscope æ—¥å¿—çº§åˆ«ä¸º WARNINGï¼Œå‡å°‘ä¸å¿…è¦çš„ä¿¡æ¯
logging.getLogger('modelscope').setLevel(logging.WARNING)

class FunASREngine:
    def __init__(self):
        try:
            # ä½¿ç”¨ redirect_stdout æ¥æ•è·è¾“å‡º
            f = io.StringIO()
            with redirect_stdout(f), redirect_stderr(f):
                # åˆå§‹åŒ–è¯­éŸ³è¯†åˆ«æ¨¡å‹
                self.model = AutoModel(
                    model="damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch",
                    model_revision="v2.0.4",
                    disable_update=True
                )
                # åˆå§‹åŒ–æ ‡ç‚¹æ¨¡å‹
                self.punc_model = AutoModel(
                    model="damo/punc_ct-transformer_zh-cn-common-vocab272727-pytorch", ## è¿™ä¸ªä¸è¦æ”¹ï¼Œæ˜¯æ­£ç¡®çš„
                    model_revision="v2.0.4"
                )
                
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            raise

    def transcribe(self, audio_data):
        """è½¬å†™éŸ³é¢‘æ•°æ®"""
        try:
            if audio_data.dtype != np.float32:
                audio_data = audio_data.astype(np.float32)
            # ä½¿ç”¨ redirect_stdout æ¥æ•è·è¾“å‡º
            f = io.StringIO()
            with redirect_stdout(f), redirect_stderr(f):
                # 1. è¯­éŸ³è¯†åˆ«
                result = self.model.generate(
                    input=audio_data,
                    batch_size_s=300,
                    use_itn=True,     # å¯ç”¨é€†æ–‡æœ¬æ­£åˆ™åŒ–
                    mode='offline',    # ä½¿ç”¨ç¦»çº¿æ¨¡å¼ä»¥è·å¾—æ›´å¥½çš„æ ‡ç‚¹æ•ˆæœ
                    decode_method='greedy_search',  # ä½¿ç”¨è´ªå©ªæœç´¢è§£ç 
                    disable_progress_bar=True  # ç¦ç”¨è¿›åº¦æ¡
                )
            
            # å¤„ç†ç»“æœ
            if isinstance(result, list) and len(result) > 0:
                text = result[0].get('text', '')
            elif isinstance(result, dict):
                text = result.get('text', '')
            else:
                text = str(result)
            
            # è¾“å‡ºåŸå§‹è½¬å†™ç»“æœ
            print(f"ğŸ¯ è¯­éŸ³è¯†åˆ«: {text}")
            
            # 2. æ·»åŠ æ ‡ç‚¹
            with redirect_stdout(f), redirect_stderr(f):
                punc_result = self.punc_model.generate(
                    input=text,
                    disable_progress_bar=True,  # ç¦ç”¨è¿›åº¦æ¡
                    batch_size=1,               # æ‰¹å¤„ç†å¤§å°
                    mode='offline',             # ç¦»çº¿æ¨¡å¼ï¼Œæ›´å‡†ç¡®çš„æ ‡ç‚¹
                    cache_size=0,               # ä¸ä½¿ç”¨ç¼“å­˜ï¼Œæ¯æ¬¡éƒ½é‡æ–°é¢„æµ‹
                    hotword_score=0.8,          # æé«˜çƒ­è¯æƒé‡ï¼Œä½¿æ ‡ç‚¹æ›´ä¸°å¯Œ
                    min_sentence_length=3       # æœ€å°å¥å­é•¿åº¦ï¼Œå°äºè¿™ä¸ªé•¿åº¦çš„ä¸ä¼šåŠ å¥å·
                )
            if isinstance(punc_result, list) and len(punc_result) > 0:
                text = punc_result[0].get('text', text)
            elif isinstance(punc_result, dict):
                text = punc_result.get('text', text)
            
            print(f"ğŸ¯ æ·»åŠ æ ‡ç‚¹: {text}")
            
            # 3. å¤„ç†è‹±æ–‡å•è¯é—´çš„ç©ºæ ¼
            processed_text = self._process_text(text)
            print(f"âœ¨ å¤„ç†åæ–‡æœ¬: {processed_text}")
            
            return [{"text": processed_text}]
            
        except Exception as e:
            print(f"âŒ è½¬å†™å¤±è´¥: {e}")
            raise

    def _process_text(self, text):
        """å¤„ç†æ–‡æœ¬ï¼Œæ·»åŠ è‹±æ–‡å•è¯é—´çš„ç©ºæ ¼"""
        # 1. ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åˆ†ç¦»è‹±æ–‡å•è¯
        def split_english_words(text):
            # åŒ¹é…è¿ç»­çš„è‹±æ–‡å­—æ¯
            words = re.finditer(r'[a-zA-Z]+', text)
            result = []
            last_end = 0
            
            for match in words:
                start, end = match.span()
                # æ·»åŠ éè‹±æ–‡éƒ¨åˆ†
                if start > last_end:
                    result.append(text[last_end:start])
                # æ·»åŠ è‹±æ–‡å•è¯
                word = match.group()
                # ä½¿ç”¨ç®€å•çš„è§„åˆ™åˆ†å‰²è‹±æ–‡å•è¯
                # æ¯”å¦‚ "whatareyou" -> "what are you"
                sub_words = []
                current_word = ""
                for i, char in enumerate(word.lower()):
                    current_word += char
                    # å¸¸è§çš„è‹±æ–‡å•è¯
                    common_words = {'what', 'are', 'you', 'doing', 'how', 'is', 'the', 'this', 'that', 'have', 'has', 'had', 'will', 'would', 'can', 'could', 'should', 'must', 'may', 'might', 'shall'}
                    # å¦‚æœå½“å‰ç§¯ç´¯çš„å­—æ¯æ„æˆäº†ä¸€ä¸ªå¸¸è§å•è¯ï¼Œå¹¶ä¸”å‰©ä½™çš„å­—æ¯ä¹Ÿå¯èƒ½æ„æˆå•è¯
                    if current_word in common_words and i < len(word) - 1:
                        sub_words.append(current_word)
                        current_word = ""
                if current_word:
                    sub_words.append(current_word)
                result.append(' '.join(sub_words))
                last_end = end
            
            # æ·»åŠ å‰©ä½™çš„æ–‡æœ¬
            if last_end < len(text):
                result.append(text[last_end:])
            
            return ''.join(result)
        
        # 2. å¤„ç†æ–‡æœ¬
        processed_text = split_english_words(text)
        
        return processed_text

    def get_model_path(self):
        return "ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹"